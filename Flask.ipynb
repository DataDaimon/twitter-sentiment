{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d74428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d988a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e698b27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the dataset\n",
    "data = pd.read_csv('twitter_sentiments.csv')\n",
    "# view the top rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "364f43b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25569, 3), (6393, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split\n",
    "train, test = train_test_split(data, test_size = 0.2, stratify = data['label'], random_state=21)\n",
    "\n",
    "# get the shape of train and test split.\n",
    "train.shape, test.shape\n",
    "## >> ((25569, 3), (6393, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8408ba81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=1000,\n",
       "                stop_words=frozenset({&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;across&#x27;, &#x27;after&#x27;,\n",
       "                                      &#x27;afterwards&#x27;, &#x27;again&#x27;, &#x27;against&#x27;, &#x27;all&#x27;,\n",
       "                                      &#x27;almost&#x27;, &#x27;alone&#x27;, &#x27;along&#x27;, &#x27;already&#x27;,\n",
       "                                      &#x27;also&#x27;, &#x27;although&#x27;, &#x27;always&#x27;, &#x27;am&#x27;,\n",
       "                                      &#x27;among&#x27;, &#x27;amongst&#x27;, &#x27;amoungst&#x27;, &#x27;amount&#x27;,\n",
       "                                      &#x27;an&#x27;, &#x27;and&#x27;, &#x27;another&#x27;, &#x27;any&#x27;, &#x27;anyhow&#x27;,\n",
       "                                      &#x27;anyone&#x27;, &#x27;anything&#x27;, &#x27;anyway&#x27;,\n",
       "                                      &#x27;anywhere&#x27;, ...}))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1000,\n",
       "                stop_words=frozenset({&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;across&#x27;, &#x27;after&#x27;,\n",
       "                                      &#x27;afterwards&#x27;, &#x27;again&#x27;, &#x27;against&#x27;, &#x27;all&#x27;,\n",
       "                                      &#x27;almost&#x27;, &#x27;alone&#x27;, &#x27;along&#x27;, &#x27;already&#x27;,\n",
       "                                      &#x27;also&#x27;, &#x27;although&#x27;, &#x27;always&#x27;, &#x27;am&#x27;,\n",
       "                                      &#x27;among&#x27;, &#x27;amongst&#x27;, &#x27;amoungst&#x27;, &#x27;amount&#x27;,\n",
       "                                      &#x27;an&#x27;, &#x27;and&#x27;, &#x27;another&#x27;, &#x27;any&#x27;, &#x27;anyhow&#x27;,\n",
       "                                      &#x27;anyone&#x27;, &#x27;anything&#x27;, &#x27;anyway&#x27;,\n",
       "                                      &#x27;anywhere&#x27;, ...}))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=1000,\n",
       "                stop_words=frozenset({'a', 'about', 'above', 'across', 'after',\n",
       "                                      'afterwards', 'again', 'against', 'all',\n",
       "                                      'almost', 'alone', 'along', 'already',\n",
       "                                      'also', 'although', 'always', 'am',\n",
       "                                      'among', 'amongst', 'amoungst', 'amount',\n",
       "                                      'an', 'and', 'another', 'any', 'anyhow',\n",
       "                                      'anyone', 'anything', 'anyway',\n",
       "                                      'anywhere', ...}))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a TF-IDF vectorizer object\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase= True, max_features=1000, stop_words=ENGLISH_STOP_WORDS)\n",
    "\n",
    "# fit the object with the training data tweets\n",
    "tfidf_vectorizer.fit(train.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "916e6602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the train and test data\n",
    "train_idf = tfidf_vectorizer.transform(train.tweet)\n",
    "test_idf  = tfidf_vectorizer.transform(test.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed6fc388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45751633986928114"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the object of LinearRegression Model\n",
    "model_LR = LogisticRegression()\n",
    "\n",
    "# fit the model with the training data\n",
    "model_LR.fit(train_idf, train.label)\n",
    "\n",
    "# predict the label on the traning data\n",
    "predict_train = model_LR.predict(train_idf)\n",
    "\n",
    "# predict the model on the test data\n",
    "predict_test = model_LR.predict(test_idf)\n",
    "\n",
    "# f1 score on train data\n",
    "f1_score(y_true= train.label, y_pred= predict_train)\n",
    "## >> 0.4888178913738019\n",
    "\n",
    "f1_score(y_true= test.label, y_pred= predict_test)\n",
    "## >> 0.45751633986928114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb47f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_features=1000,\n",
       "                                 stop_words=frozenset({&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;,\n",
       "                                                       &#x27;across&#x27;, &#x27;after&#x27;,\n",
       "                                                       &#x27;afterwards&#x27;, &#x27;again&#x27;,\n",
       "                                                       &#x27;against&#x27;, &#x27;all&#x27;,\n",
       "                                                       &#x27;almost&#x27;, &#x27;alone&#x27;,\n",
       "                                                       &#x27;along&#x27;, &#x27;already&#x27;,\n",
       "                                                       &#x27;also&#x27;, &#x27;although&#x27;,\n",
       "                                                       &#x27;always&#x27;, &#x27;am&#x27;, &#x27;among&#x27;,\n",
       "                                                       &#x27;amongst&#x27;, &#x27;amoungst&#x27;,\n",
       "                                                       &#x27;amount&#x27;, &#x27;an&#x27;, &#x27;and&#x27;,\n",
       "                                                       &#x27;another&#x27;, &#x27;any&#x27;,\n",
       "                                                       &#x27;anyhow&#x27;, &#x27;anyone&#x27;,\n",
       "                                                       &#x27;anything&#x27;, &#x27;anyway&#x27;,\n",
       "                                                       &#x27;anywhere&#x27;, ...}))),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_features=1000,\n",
       "                                 stop_words=frozenset({&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;,\n",
       "                                                       &#x27;across&#x27;, &#x27;after&#x27;,\n",
       "                                                       &#x27;afterwards&#x27;, &#x27;again&#x27;,\n",
       "                                                       &#x27;against&#x27;, &#x27;all&#x27;,\n",
       "                                                       &#x27;almost&#x27;, &#x27;alone&#x27;,\n",
       "                                                       &#x27;along&#x27;, &#x27;already&#x27;,\n",
       "                                                       &#x27;also&#x27;, &#x27;although&#x27;,\n",
       "                                                       &#x27;always&#x27;, &#x27;am&#x27;, &#x27;among&#x27;,\n",
       "                                                       &#x27;amongst&#x27;, &#x27;amoungst&#x27;,\n",
       "                                                       &#x27;amount&#x27;, &#x27;an&#x27;, &#x27;and&#x27;,\n",
       "                                                       &#x27;another&#x27;, &#x27;any&#x27;,\n",
       "                                                       &#x27;anyhow&#x27;, &#x27;anyone&#x27;,\n",
       "                                                       &#x27;anything&#x27;, &#x27;anyway&#x27;,\n",
       "                                                       &#x27;anywhere&#x27;, ...}))),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1000,\n",
       "                stop_words=frozenset({&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;across&#x27;, &#x27;after&#x27;,\n",
       "                                      &#x27;afterwards&#x27;, &#x27;again&#x27;, &#x27;against&#x27;, &#x27;all&#x27;,\n",
       "                                      &#x27;almost&#x27;, &#x27;alone&#x27;, &#x27;along&#x27;, &#x27;already&#x27;,\n",
       "                                      &#x27;also&#x27;, &#x27;although&#x27;, &#x27;always&#x27;, &#x27;am&#x27;,\n",
       "                                      &#x27;among&#x27;, &#x27;amongst&#x27;, &#x27;amoungst&#x27;, &#x27;amount&#x27;,\n",
       "                                      &#x27;an&#x27;, &#x27;and&#x27;, &#x27;another&#x27;, &#x27;any&#x27;, &#x27;anyhow&#x27;,\n",
       "                                      &#x27;anyone&#x27;, &#x27;anything&#x27;, &#x27;anyway&#x27;,\n",
       "                                      &#x27;anywhere&#x27;, ...}))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_features=1000,\n",
       "                                 stop_words=frozenset({'a', 'about', 'above',\n",
       "                                                       'across', 'after',\n",
       "                                                       'afterwards', 'again',\n",
       "                                                       'against', 'all',\n",
       "                                                       'almost', 'alone',\n",
       "                                                       'along', 'already',\n",
       "                                                       'also', 'although',\n",
       "                                                       'always', 'am', 'among',\n",
       "                                                       'amongst', 'amoungst',\n",
       "                                                       'amount', 'an', 'and',\n",
       "                                                       'another', 'any',\n",
       "                                                       'anyhow', 'anyone',\n",
       "                                                       'anything', 'anyway',\n",
       "                                                       'anywhere', ...}))),\n",
       "                ('model', LogisticRegression())])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the stages of the pipeline\n",
    "pipeline = Pipeline(steps= [('tfidf', TfidfVectorizer(lowercase=True,\n",
    "                                                      max_features=1000,\n",
    "                                                      stop_words= ENGLISH_STOP_WORDS)),\n",
    "                            ('model', LogisticRegression())])\n",
    "\n",
    "# fit the pipeline model with the training data                            \n",
    "pipeline.fit(train.tweet, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f4cce21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample tweet\n",
    "text = [\"Virat Kohli, AB de Villiers set to auction their 'Green Day' kits from 2016 IPL match to raise funds\"]\n",
    "\n",
    "# predict the label using the pipeline\n",
    "pipeline.predict(text)\n",
    "## >> array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a2011cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03bd5931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_classification.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump the pipeline model\n",
    "dump(pipeline, filename=\"text_classification.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "129df75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import joblib\n",
    "from joblib import load\n",
    "\n",
    "# sample tweet text\n",
    "text = [\"Virat Kohli, AB de Villiers set to auction their 'Green Day' kits from 2016 IPL match to raise funds\"]\n",
    "\n",
    "# load the saved pipleine model\n",
    "pipeline = load(\"text_classification.joblib\")\n",
    "\n",
    "# predict on the sample tweet text\n",
    "pipeline.predict(text)\n",
    "## >> array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1334d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1f14cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import tweepy\n",
    "import time\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "# api key\n",
    "api_key = \"9D6LvvCirf5d16SudvkS2SiKf\"\n",
    "# api secret key\n",
    "api_secret_key = \"5RIuJlxMfsc3drxlwibWc5qgyf2rZPPb9ZPNcTsBFDKkTEx0gf\"\n",
    "# access token\n",
    "access_token = \"1577475918192201730-nzndXCXcumuxdZfj2DkGZTrXnIxGYT\"\n",
    "# access token secret\n",
    "access_token_secret = \"bzqvlVwjcKF4h13Rwcu35aX5JvxGHVUQQ1Z65TmdNDk2G\"\n",
    "\n",
    "# authorize the API Key\n",
    "authentication = tweepy.OAuthHandler(api_key, api_secret_key)\n",
    "\n",
    "# authorization to user's access token and access token secret\n",
    "authentication.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# call the api\n",
    "api = tweepy.API(authentication, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c55f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_tweets(text_query):\n",
    "    # list to store tweets\n",
    "    tweets_list = []\n",
    "    # no of tweets\n",
    "    count = 50\n",
    "    try:\n",
    "        # Pulling individual tweets from query\n",
    "        for tweet in api.search_tweets(q=text_query, count=count):\n",
    "            print(tweet.text)\n",
    "            # Adding to list that contains all tweets\n",
    "            tweets_list.append({'created_at': tweet.created_at,\n",
    "                                'tweet_id': tweet.id,\n",
    "                                'tweet_text': tweet.text})\n",
    "        return pd.DataFrame.from_dict(tweets_list)\n",
    "\n",
    "    except BaseException as e:\n",
    "        print('failed on_status,', str(e))\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f39609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_tweets import get_related_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "767e3959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "from flask import Flask, render_template, request, redirect, url_for\n",
    "from joblib import load\n",
    "\n",
    "\n",
    "# load the pipeline object\n",
    "pipeline = load(\"text_classification.joblib\")\n",
    "\n",
    "# function to get results for a particular text query\n",
    "def requestResults(name):\n",
    "    # get the tweets text\n",
    "    tweets = get_related_tweets(name)\n",
    "    # get the prediction\n",
    "    tweets['prediction'] = pipeline.predict(tweets['tweet_text'])\n",
    "    # get the value counts of different labels predicted\n",
    "    data = str(tweets.prediction.value_counts()) + '\\n\\n'\n",
    "    return data + str(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be2d5566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# render default webpage\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('home.html')\n",
    "\n",
    "# when the post method detect, then redirect to success function\n",
    "@app.route('/', methods=['POST', 'GET'])\n",
    "def get_data():\n",
    "    if request.method == 'POST':\n",
    "        user = request.form['search']\n",
    "        return redirect(url_for('success', name=user))\n",
    "\n",
    "# get the data for the requested query\n",
    "@app.route('/success/<name>')\n",
    "def success(name):\n",
    "    return \"<xmp>\" + str(requestResults(name)) + \" </xmp> \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c64d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [04/Dec/2022 16:55:43] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Dec/2022 16:55:43] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [04/Dec/2022 16:55:48] \"POST / HTTP/1.1\" 302 -\n",
      "127.0.0.1 - - [04/Dec/2022 16:55:49] \"GET /success/elon%20musk HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @theRealKiyosaki: Why Silicon Valley‚Äôs WOKE fear MUSK: Musk is an entrepreneur.  He does not need a job or money. He beat BIG BANKS with‚Ä¶\n",
      "RT @OzraeliAvi: #BREAKING: Elon Musk confirms he is NOT suicidal in case they Epstein him.\n",
      "RT @bnews_oficial: Suspeita: Twitter beneficiou esquerda nas elei√ß√µes do Brasil, diz Elon Musk\n",
      "https://t.co/LbrSv9uDZg\n",
      "RT @HukAleksandra: Elon Musk could retire and ride off into the sunset, yet he chose to fight corruption. It‚Äôs incredible really.\n",
      "RT @ChuckCallesto: BREAKING NOW: Elon Musk Suggests Labeling Certain CORPORATE MEDIA OUTLETS as State Sponsored Media..\n",
      "RT @realTuckFrumper: Even Right-Wingers Think Elon Musk‚Äôs Hunter Biden Reveal Is A Nothingburger https://t.co/lSQMr2XOpL\n",
      "RT @YvesPDB: HUNTER BIDEN, toxico et p√©dophile, c‚Äô√©tait bien vrai! Elon Musk fournit les preuves de la censure pour ne pas √©bruiter le scan‚Ä¶\n",
      "RT @vanessavallej0: ‚Äú¬°Si cometo suicidio no es real!‚Äù\n",
      "\n",
      "Elon Musk acaba de decir esto en un Space en Twitter. Parece que el nuevo due√±o de l‚Ä¶\n",
      "RT @fellipebambam: ‚Äì Ei, Elon Musk, voc√™ pode descobrir quais outras elei√ß√µes foram ‚Äúmanipuladas‚Äù pelo antigo regime do Twitter. Obrigado ‚Äì‚Ä¶\n",
      "RT @theRealKiyosaki: Why Silicon Valley‚Äôs WOKE fear MUSK: Musk is an entrepreneur.  He does not need a job or money. He beat BIG BANKS with‚Ä¶\n",
      "RT @ClayTravis: Elon Musk says Apple has resumed all of their advertising on Twitter.\n",
      "@JuddLegum üòÇ Democrats have been violating the Constitution for the last 10 years!\n",
      "\n",
      "Right now they‚Äôre trying to do‚Ä¶ https://t.co/EuWGNOLHKA\n",
      "RT @OzraeliAvi: #BREAKING: Elon Musk confirms he is NOT suicidal in case they Epstein him.\n",
      "RT @ChuckCallesto: BREAKING NOW: Elon Musk Suggests Labeling Certain CORPORATE MEDIA OUTLETS as State Sponsored Media..\n",
      "RT @ThisIsKyleR: Elon Musk is giving Americans the best early Christmas present, truth being brought to light.\n",
      "RT @dupontaignan: D√©claration scandaleuse d‚ÄôEmmanuel Macron qui qualifie de ¬´ gros probl√®me ¬ª la gestion de Musk sur Twitter.\n",
      "La v√©rit√© est‚Ä¶\n",
      "RT @catturd2: What Elon Musk revealed yesterday is the Biden regime is the most corrupt pResidency in U.S. history. \n",
      "\n",
      "These are all slimy,‚Ä¶\n",
      "RT @PDrBesserwisser: Zwei wesentliche Erkenntnisse aus den letzten zwei Tagen:\n",
      "\n",
      "1. Elon Musk legt interne Twitter Dokumente offen, wonach T‚Ä¶\n",
      "@HistoryInPics Wow, this page has changed a lot - being mostly about Elon Musk no one else ..isn't it kinda ridiculous? Eh #bye\n",
      "RT @LayahHeilpern: Elon Musk and Andrew Tate are the two most influential men of 2022. I don't make the rules, these are the facts.\n",
      "RT @Reuters: WATCH: Elon Musk has picked a public fight with Apple. Two companies, giant Spotify, and Epic Games, may be glad that he did h‚Ä¶\n",
      "RT @NickAdamsinUSA: Elon Musk is the world‚Äôs richest whistleblower.\n",
      "RT @3xAcide: Elon Musk: ¬´Orwell 1984 is not supposed to be an instruction manual.¬†¬ª\n",
      "RT @theRealKiyosaki: Why Silicon Valley‚Äôs WOKE fear MUSK: Musk is an entrepreneur.  He does not need a job or money. He beat BIG BANKS with‚Ä¶\n",
      "RT @YvesPDB: HUNTER BIDEN, toxico et p√©dophile, c‚Äô√©tait bien vrai! Elon Musk fournit les preuves de la censure pour ne pas √©bruiter le scan‚Ä¶\n",
      "RT @OzraeliAvi: The mainstream media is officially LOSING its war on Elon Musk.\n",
      "RT @CollinRugg: Elon Musk is going up against some of the most powerful people in America.\n",
      "\n",
      "Pray for him.\n",
      "‚ÄºÔ∏èBREAKING‚ÄºÔ∏èDE BEERPUT GAAT OPEN‚ÄºÔ∏è\n",
      "LIEVE FOLLOWERS HEBBEN JULLIE WEL IN DE GATEN WAT ELON MUSK NU DOET! \n",
      "MET ZIJN ‚Äú‚Ä¶ https://t.co/e1Jr54riih\n",
      "RT @CapitanBitcoin: Elon Musk desvela que Twitter recib√≠a instrucciones pol√≠ticas del partido dem√≥crata v√≠a mail para cancelar tuits y susp‚Ä¶\n",
      "RT @ChanceGardiner: Elon Musk nelle ultime 24 ore avrebbe rimosso da Tuitter 44.000 profili di materiale di sfruttamento sessuale di minori‚Ä¶\n",
      "RT @ChuckCallesto: BREAKING REPORT: Elon Musk Drops MOAB ‚Äì Says The New York Times has become an 'UNREGISTERED LOBBYING FIRM for far left p‚Ä¶\n",
      "RT @w_terrence: Elon Musk will go down as one of the greatest African Americans in US history and Obama will go down as one of the worst an‚Ä¶\n",
      "RT @thedailybeast: Elon Musk is seen as a supervillain for using $44 billion of his own money to buy Twitter but Sam Bankman-Fried is treat‚Ä¶\n",
      "RT @Ant52529536Jose: Sexo, drogas, armas, prostitutas, dinero negro y CENSURA en redes sociales. Elon Musk revela c√≥mo Twitter censur√≥ sin‚Ä¶\n",
      "RT @ACTBrigitte: Why isn't the mainstream media talking about Elon Musk's Twitter files dump?\n",
      "RT @realJoelFischer: Hillary knitting a Christmas scarf for Elon Musk. https://t.co/A8JGC6YANi\n",
      "RT @NotHoodlum: Right-Wingers on Musk‚Äôs overhyped Twitter Files‚Äô. \n",
      "\n",
      "‚ÄúI‚Äôm deeply underwhelmed.‚Äù- Sebastian Gorka\n",
      "\n",
      "‚ÄúIt wasn‚Äôt the smoking gun‚Ä¶\n",
      "RT @ThisIsKyleR: Elon Musk is giving Americans the best early Christmas present, truth being brought to light.\n",
      "RT @theRealKiyosaki: Why Silicon Valley‚Äôs WOKE fear MUSK: Musk is an entrepreneur.  He does not need a job or money. He beat BIG BANKS with‚Ä¶\n",
      "RT @ThisIsKyleR: Elon Musk might have gained quite a few enemies tonight, but he also gained so many supporters. @elonmusk\n",
      "RT @eduardomenoni: Elon Musk est√° destapando toda la atroz censura que ordenaron los dem√≥cratas contra Trump y los patriotas en EEUU. Esto‚Ä¶\n",
      "RT @JuanitoSay: ¬øSe acuerdan que en 2020 salio una informacion sobre una supuesta computadora de Hunter Biden, hijo de Elon Musk y todos lo‚Ä¶\n",
      "RT @StephenKing: Shops used to have a sign saying, IF YOU BREAK IT, YOU OWN IT.\n",
      "Elon Musk's motto seems to be, I OWN IT, SO NOW I'LL BREAK‚Ä¶\n",
      "RT @rodrigomarcial_: Elon Musk seria preso aqui no Brasil se  fizesse alega√ß√µes sobre nossas elei√ß√µes parecidas com o que falou ontem sobre‚Ä¶\n",
      "RT @ElliotStabler92: Wieso haben die Angst vor Elon #Musk?üòú https://t.co/irdiQ8cjI5\n",
      "RT @thebradfordfile: Elon Musk: \"Twitter has done more to stop child exploitation in the last month than probably the last ten years. That'‚Ä¶\n",
      "RT @cb_doge: \"If I committed suicide, it is not real.\"  ‚Äî Elon Musk, just now on Twitter Spaces\n",
      "\n",
      "Protect @elonmusk at all costs, he is free‚Ä¶\n",
      "RT @EvasTeslaSPlaid: Who thinks Twitter is more fun now than before Elon Musk‚Äôs ownership? @elonmusk\n",
      "RT @AhmedBaba_: So Elon Musk coordinated a leak attempting to accuse the Biden Admin of pressuring Twitter content moderation.\n",
      "\n",
      "What he end‚Ä¶\n",
      "@TheMoonCarl Elon Musk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Dec/2022 16:55:49] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "app.run(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
