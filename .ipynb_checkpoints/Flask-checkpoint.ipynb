{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d74428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d988a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e698b27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the dataset\n",
    "data = pd.read_csv('twitter_sentiments.csv')\n",
    "# view the top rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "364f43b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25569, 3), (6393, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split\n",
    "train, test = train_test_split(data, test_size = 0.2, stratify = data['label'], random_state=21)\n",
    "\n",
    "# get the shape of train and test split.\n",
    "train.shape, test.shape\n",
    "## >> ((25569, 3), (6393, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8408ba81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=1000,\n",
       "                stop_words=frozenset({&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;across&#x27;, &#x27;after&#x27;,\n",
       "                                      &#x27;afterwards&#x27;, &#x27;again&#x27;, &#x27;against&#x27;, &#x27;all&#x27;,\n",
       "                                      &#x27;almost&#x27;, &#x27;alone&#x27;, &#x27;along&#x27;, &#x27;already&#x27;,\n",
       "                                      &#x27;also&#x27;, &#x27;although&#x27;, &#x27;always&#x27;, &#x27;am&#x27;,\n",
       "                                      &#x27;among&#x27;, &#x27;amongst&#x27;, &#x27;amoungst&#x27;, &#x27;amount&#x27;,\n",
       "                                      &#x27;an&#x27;, &#x27;and&#x27;, &#x27;another&#x27;, &#x27;any&#x27;, &#x27;anyhow&#x27;,\n",
       "                                      &#x27;anyone&#x27;, &#x27;anything&#x27;, &#x27;anyway&#x27;,\n",
       "                                      &#x27;anywhere&#x27;, ...}))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1000,\n",
       "                stop_words=frozenset({&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;across&#x27;, &#x27;after&#x27;,\n",
       "                                      &#x27;afterwards&#x27;, &#x27;again&#x27;, &#x27;against&#x27;, &#x27;all&#x27;,\n",
       "                                      &#x27;almost&#x27;, &#x27;alone&#x27;, &#x27;along&#x27;, &#x27;already&#x27;,\n",
       "                                      &#x27;also&#x27;, &#x27;although&#x27;, &#x27;always&#x27;, &#x27;am&#x27;,\n",
       "                                      &#x27;among&#x27;, &#x27;amongst&#x27;, &#x27;amoungst&#x27;, &#x27;amount&#x27;,\n",
       "                                      &#x27;an&#x27;, &#x27;and&#x27;, &#x27;another&#x27;, &#x27;any&#x27;, &#x27;anyhow&#x27;,\n",
       "                                      &#x27;anyone&#x27;, &#x27;anything&#x27;, &#x27;anyway&#x27;,\n",
       "                                      &#x27;anywhere&#x27;, ...}))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=1000,\n",
       "                stop_words=frozenset({'a', 'about', 'above', 'across', 'after',\n",
       "                                      'afterwards', 'again', 'against', 'all',\n",
       "                                      'almost', 'alone', 'along', 'already',\n",
       "                                      'also', 'although', 'always', 'am',\n",
       "                                      'among', 'amongst', 'amoungst', 'amount',\n",
       "                                      'an', 'and', 'another', 'any', 'anyhow',\n",
       "                                      'anyone', 'anything', 'anyway',\n",
       "                                      'anywhere', ...}))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a TF-IDF vectorizer object\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase= True, max_features=1000, stop_words=ENGLISH_STOP_WORDS)\n",
    "\n",
    "# fit the object with the training data tweets\n",
    "tfidf_vectorizer.fit(train.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "916e6602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the train and test data\n",
    "train_idf = tfidf_vectorizer.transform(train.tweet)\n",
    "test_idf  = tfidf_vectorizer.transform(test.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed6fc388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45751633986928114"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the object of LinearRegression Model\n",
    "model_LR = LogisticRegression()\n",
    "\n",
    "# fit the model with the training data\n",
    "model_LR.fit(train_idf, train.label)\n",
    "\n",
    "# predict the label on the traning data\n",
    "predict_train = model_LR.predict(train_idf)\n",
    "\n",
    "# predict the model on the test data\n",
    "predict_test = model_LR.predict(test_idf)\n",
    "\n",
    "# f1 score on train data\n",
    "f1_score(y_true= train.label, y_pred= predict_train)\n",
    "## >> 0.4888178913738019\n",
    "\n",
    "f1_score(y_true= test.label, y_pred= predict_test)\n",
    "## >> 0.45751633986928114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb47f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_features=1000,\n",
       "                                 stop_words=frozenset({&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;,\n",
       "                                                       &#x27;across&#x27;, &#x27;after&#x27;,\n",
       "                                                       &#x27;afterwards&#x27;, &#x27;again&#x27;,\n",
       "                                                       &#x27;against&#x27;, &#x27;all&#x27;,\n",
       "                                                       &#x27;almost&#x27;, &#x27;alone&#x27;,\n",
       "                                                       &#x27;along&#x27;, &#x27;already&#x27;,\n",
       "                                                       &#x27;also&#x27;, &#x27;although&#x27;,\n",
       "                                                       &#x27;always&#x27;, &#x27;am&#x27;, &#x27;among&#x27;,\n",
       "                                                       &#x27;amongst&#x27;, &#x27;amoungst&#x27;,\n",
       "                                                       &#x27;amount&#x27;, &#x27;an&#x27;, &#x27;and&#x27;,\n",
       "                                                       &#x27;another&#x27;, &#x27;any&#x27;,\n",
       "                                                       &#x27;anyhow&#x27;, &#x27;anyone&#x27;,\n",
       "                                                       &#x27;anything&#x27;, &#x27;anyway&#x27;,\n",
       "                                                       &#x27;anywhere&#x27;, ...}))),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_features=1000,\n",
       "                                 stop_words=frozenset({&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;,\n",
       "                                                       &#x27;across&#x27;, &#x27;after&#x27;,\n",
       "                                                       &#x27;afterwards&#x27;, &#x27;again&#x27;,\n",
       "                                                       &#x27;against&#x27;, &#x27;all&#x27;,\n",
       "                                                       &#x27;almost&#x27;, &#x27;alone&#x27;,\n",
       "                                                       &#x27;along&#x27;, &#x27;already&#x27;,\n",
       "                                                       &#x27;also&#x27;, &#x27;although&#x27;,\n",
       "                                                       &#x27;always&#x27;, &#x27;am&#x27;, &#x27;among&#x27;,\n",
       "                                                       &#x27;amongst&#x27;, &#x27;amoungst&#x27;,\n",
       "                                                       &#x27;amount&#x27;, &#x27;an&#x27;, &#x27;and&#x27;,\n",
       "                                                       &#x27;another&#x27;, &#x27;any&#x27;,\n",
       "                                                       &#x27;anyhow&#x27;, &#x27;anyone&#x27;,\n",
       "                                                       &#x27;anything&#x27;, &#x27;anyway&#x27;,\n",
       "                                                       &#x27;anywhere&#x27;, ...}))),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1000,\n",
       "                stop_words=frozenset({&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;across&#x27;, &#x27;after&#x27;,\n",
       "                                      &#x27;afterwards&#x27;, &#x27;again&#x27;, &#x27;against&#x27;, &#x27;all&#x27;,\n",
       "                                      &#x27;almost&#x27;, &#x27;alone&#x27;, &#x27;along&#x27;, &#x27;already&#x27;,\n",
       "                                      &#x27;also&#x27;, &#x27;although&#x27;, &#x27;always&#x27;, &#x27;am&#x27;,\n",
       "                                      &#x27;among&#x27;, &#x27;amongst&#x27;, &#x27;amoungst&#x27;, &#x27;amount&#x27;,\n",
       "                                      &#x27;an&#x27;, &#x27;and&#x27;, &#x27;another&#x27;, &#x27;any&#x27;, &#x27;anyhow&#x27;,\n",
       "                                      &#x27;anyone&#x27;, &#x27;anything&#x27;, &#x27;anyway&#x27;,\n",
       "                                      &#x27;anywhere&#x27;, ...}))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_features=1000,\n",
       "                                 stop_words=frozenset({'a', 'about', 'above',\n",
       "                                                       'across', 'after',\n",
       "                                                       'afterwards', 'again',\n",
       "                                                       'against', 'all',\n",
       "                                                       'almost', 'alone',\n",
       "                                                       'along', 'already',\n",
       "                                                       'also', 'although',\n",
       "                                                       'always', 'am', 'among',\n",
       "                                                       'amongst', 'amoungst',\n",
       "                                                       'amount', 'an', 'and',\n",
       "                                                       'another', 'any',\n",
       "                                                       'anyhow', 'anyone',\n",
       "                                                       'anything', 'anyway',\n",
       "                                                       'anywhere', ...}))),\n",
       "                ('model', LogisticRegression())])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the stages of the pipeline\n",
    "pipeline = Pipeline(steps= [('tfidf', TfidfVectorizer(lowercase=True,\n",
    "                                                      max_features=1000,\n",
    "                                                      stop_words= ENGLISH_STOP_WORDS)),\n",
    "                            ('model', LogisticRegression())])\n",
    "\n",
    "# fit the pipeline model with the training data                            \n",
    "pipeline.fit(train.tweet, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f4cce21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample tweet\n",
    "text = [\"Virat Kohli, AB de Villiers set to auction their 'Green Day' kits from 2016 IPL match to raise funds\"]\n",
    "\n",
    "# predict the label using the pipeline\n",
    "pipeline.predict(text)\n",
    "## >> array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a2011cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03bd5931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_classification.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump the pipeline model\n",
    "dump(pipeline, filename=\"text_classification.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "129df75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import joblib\n",
    "from joblib import load\n",
    "\n",
    "# sample tweet text\n",
    "text = [\"Virat Kohli, AB de Villiers set to auction their 'Green Day' kits from 2016 IPL match to raise funds\"]\n",
    "\n",
    "# load the saved pipleine model\n",
    "pipeline = load(\"text_classification.joblib\")\n",
    "\n",
    "# predict on the sample tweet text\n",
    "pipeline.predict(text)\n",
    "## >> array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1334d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1f14cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import tweepy\n",
    "import time\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "# api key\n",
    "api_key = \"9D6LvvCirf5d16SudvkS2SiKf\"\n",
    "# api secret key\n",
    "api_secret_key = \"5RIuJlxMfsc3drxlwibWc5qgyf2rZPPb9ZPNcTsBFDKkTEx0gf\"\n",
    "# access token\n",
    "access_token = \"1577475918192201730-nzndXCXcumuxdZfj2DkGZTrXnIxGYT\"\n",
    "# access token secret\n",
    "access_token_secret = \"bzqvlVwjcKF4h13Rwcu35aX5JvxGHVUQQ1Z65TmdNDk2G\"\n",
    "\n",
    "# authorize the API Key\n",
    "authentication = tweepy.OAuthHandler(api_key, api_secret_key)\n",
    "\n",
    "# authorization to user's access token and access token secret\n",
    "authentication.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# call the api\n",
    "api = tweepy.API(authentication, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c55f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_tweets(text_query):\n",
    "    # list to store tweets\n",
    "    tweets_list = []\n",
    "    # no of tweets\n",
    "    count = 50\n",
    "    try:\n",
    "        # Pulling individual tweets from query\n",
    "        for tweet in api.search_tweets(q=text_query, count=count):\n",
    "            print(tweet.text)\n",
    "            # Adding to list that contains all tweets\n",
    "            tweets_list.append({'created_at': tweet.created_at,\n",
    "                                'tweet_id': tweet.id,\n",
    "                                'tweet_text': tweet.text})\n",
    "        return pd.DataFrame.from_dict(tweets_list)\n",
    "\n",
    "    except BaseException as e:\n",
    "        print('failed on_status,', str(e))\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f39609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_tweets import get_related_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "767e3959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "from flask import Flask, render_template, request, redirect, url_for\n",
    "from joblib import load\n",
    "\n",
    "\n",
    "# load the pipeline object\n",
    "pipeline = load(\"text_classification.joblib\")\n",
    "\n",
    "# function to get results for a particular text query\n",
    "def requestResults(name):\n",
    "    # get the tweets text\n",
    "    tweets = get_related_tweets(name)\n",
    "    # get the prediction\n",
    "    tweets['prediction'] = pipeline.predict(tweets['tweet_text'])\n",
    "    # get the value counts of different labels predicted\n",
    "    data = str(tweets.prediction.value_counts()) + '\\n\\n'\n",
    "    return data + str(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be2d5566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# render default webpage\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('home.html')\n",
    "\n",
    "# when the post method detect, then redirect to success function\n",
    "@app.route('/', methods=['POST', 'GET'])\n",
    "def get_data():\n",
    "    if request.method == 'POST':\n",
    "        user = request.form['search']\n",
    "        return redirect(url_for('success', name=user))\n",
    "\n",
    "# get the data for the requested query\n",
    "@app.route('/success/<name>')\n",
    "def success(name):\n",
    "    return \"<xmp>\" + str(requestResults(name)) + \" </xmp> \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c64d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [22/Nov/2022 10:19:09] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Nov/2022 10:19:14] \"POST / HTTP/1.1\" 302 -\n",
      "127.0.0.1 - - [22/Nov/2022 10:19:15] \"GET /success/trump HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@KK4176 @DTNutt @Leslieoo7 Lol every time you tweet you prove how ignorant you are. You can check my timeline to se‚Ä¶ https://t.co/l9NgAHaXBs\n",
      "RT @OccupyDemocrats: BREAKING: First Lady Jill Biden happily welcomes the Christmas tree to the White House, says it‚Äôs ‚Äúbeautiful‚Äù and she‚Ä¶\n",
      "RT @monicaonairtalk: The premiere that may have ended Donald Trump‚Äôs candidacy &amp; will hopefully lead to the indictment of Pfizer &amp; Modena e‚Ä¶\n",
      "@ICheckertm @BulowMatthew @JD_Wallen1 @RepAdamSchiff https://t.co/Yl1qAivUpP\n",
      "RT @PalmerReport: 1) Manhattan DA Alvin Bragg is leaking that he‚Äôs looking at criminally charging Donald Trump in the Stormy Daniels scanda‚Ä¶\n",
      "RT @MattBinder: no doubt about it: Donald Trump was absolutely telling the truth about his meeting with Elon Musk. \n",
      "\n",
      "he's doing it right no‚Ä¶\n",
      "RT @Elizabe99819964: @tribelaw @AshaRangappa_ I just hope the net is flung wide enough to include both the Senate and the House.  There are‚Ä¶\n",
      "RT @Bit2Loud: @TimRunsHisMouth @elonmusk They were, but trump (a suspect) compromised the investigation by having Maxwell intercepted in pr‚Ä¶\n",
      "@GuntherEagleman My Prez Trump\n",
      "RT @w_terrence: Biden cares about black votes.\n",
      "\n",
      "Trump cares about black people. \n",
      "\n",
      "End of story.\n",
      "RT @lavern_spicer: She‚Äôs making a strong case for Trump‚Äôs candidacy with that statement. https://t.co/YXMoK7fEs0\n",
      "@whitlock_anne @lavern_spicer Sounds like something a Republican would say. Got it?\n",
      "@ilyrightback And him liking anti trump tweets back in 19/20 and being a child of a refugee and queer means nothing??? It‚Äôs weird\n",
      "@newkingej @w_terrence Yep very true I like Trump but if Desantis runs I'm voting for him we need something new and fresh\n",
      "RT @RadioFreeTom: For some left-leaning Twitter users, simply staying online could feel like a small step toward saving democracy, @kait_ti‚Ä¶\n",
      "RT @TheBabylonBee: Taliban Quits Twitter To Protest Return Of Trump https://t.co/zu0SBsmlMi\n",
      "RT @TheBabylonBee: Taliban Quits Twitter To Protest Return Of Trump https://t.co/zu0SBsmlMi\n",
      "@BrendaRuffin13 @LynnGre31717113 @LBJFKploitics @TeamPelosi Trump 2024\n",
      "@OccupyDemocrats Funny coming from a guy who's said for year's he had hard evidence Trump was connected to Russia,‚Ä¶ https://t.co/D2a2lU4TH1\n",
      "@Zeednuts @swtdreams1007 @Riflh97 @guelphgirlchris @lavern_spicer No instead they had to hide his staff that wasn‚Äôt‚Ä¶ https://t.co/diuFuZuD9d\n",
      "If the DA is coming after Trump for this THAT just makes him more ADMIRED by the American people because we don‚Äôt c‚Ä¶ https://t.co/oqDE2RB7rb\n",
      "RT @LongTimeHistory: #wtpBLUE #ONEV1 #FreshResists\n",
      "\n",
      "TODAY IN HISTORY\n",
      "\n",
      "1986 ‚Äî Oliver North¬†&amp; secretary shred documents implicating them in¬†I‚Ä¶\n",
      "@carita_paige @Steve_Gallardo @CaptMarkKelly @katiehobbs @Adrian_Fontes @krismayes Trump this, Trump that, every De‚Ä¶ https://t.co/64LmjR6JGV\n",
      "RT @BaddCompani: Mike Pompeo interfered in the Peaceful Transfer of Power\n",
      "\n",
      "Stating, and I basically quote:\n",
      "\n",
      "'There will be a Peaceful Trans‚Ä¶\n",
      "RT @evoespueblo: Trump reivindica las pol√≠ticas intervencionistas de la Casa Blanca y hace un llamado desesperado a \"detener la expansi√≥n d‚Ä¶\n",
      "Column: Trump running in 2024 is a dream come true for Democrats. He‚Äôs the weakest candidate out¬†there https://t.co/wpNB6ReLec\n",
      "RT @OccupyDemocrats: BREAKING: First Lady Jill Biden happily welcomes the Christmas tree to the White House, says it‚Äôs ‚Äúbeautiful‚Äù and she‚Ä¶\n",
      "@SariSwiff @Benguin420 @AresOfRivia @RollingStone Not jack or trent....because they no like trump...ü§°\n",
      "RT @sandibachom: @ShotwellNancy I‚Äôm not going anywhere.  I‚Äôm used to toxic environments. I was in Charlottesville and the Capitol and filme‚Ä¶\n",
      "RT @zerohedge: The Lords Of War: The Perils Facing Trump, Garland, &amp; Smith In Washington's Legal Arms Race https://t.co/OhKE2rtsbN\n",
      "Donald Trump tried to stir novelists on behalf of a grocery store.\n",
      "RT @ClayTravis: Two years ago Donald Trump told CBS‚Äôs Lesley Stahl on 60 Minutes the Hunter Biden laptop was real and should be covered by‚Ä¶\n",
      "RT @leftistlitwick: tbh i think the underlying reason behind the midterms going so badly for Republicans is that they misconstrued Trump wi‚Ä¶\n",
      "@Shorbri72 @wes120121 @ericareport You read current events like some Christians read the Bible. You don't get to pi‚Ä¶ https://t.co/QqpDYBBvl6\n",
      "RT @lindyli: Evangelicals gave us Trump\n",
      "\n",
      "Evangelicals gave us the ChristoFascist Supreme Court that destroyed our reproductive rights\n",
      "\n",
      "Evan‚Ä¶\n",
      "Beltway Insider: Biden/G20, GOP/House, Russia/Ukraine, COVID/Vaccine Totals, Musk/Trump, Elizabeth Holmes https://t.co/eBYyGCXF3r\n",
      "RT @OccupyDemocrats: BREAKING: New York Times \"Trump whisperer\" Maggie Haberman reveals that \"his heart\" isn't in running because he \"wants‚Ä¶\n",
      "RT @RollingStone: Jack White is no longer on Twitter: ‚ÄúSo you gave Trump his Twitter platform back. Absolutely disgusting, Elon.‚Äù https://t‚Ä¶\n",
      "RT @MayoIsSpicyy: Trump is a fucking loser and the GOP knows it.\n",
      "RT @ddanpereira: Manhattan DA Alvin Bragg may be revisiting the Stormy Daniels hush money cover up led by Individual 1, Donald Trump. Only‚Ä¶\n",
      "This guy is desperate for attention, it's really great he found it in the arms of CNN. \n",
      "\n",
      "https://t.co/mFtzeuDq6p\n",
      "@WmMcKinley25 @kyledcheney \"The U.S. intelligence community‚Äôs conclusion that Russia interfered in the 2016 electio‚Ä¶ https://t.co/lA11Za9LlA\n",
      "RT @TribelSocial: Out official statement on Elon Musk reinstating Trump‚Äôs Twitter account: ‚ÄúUnlike Musk, our main focus is not generating a‚Ä¶\n",
      "RT @ungerbn103: Trump stole and lied about 27 boxes of Top Secret and Classified Documents and he is allowed to run for President again.\n",
      "\n",
      "E‚Ä¶\n",
      "RT @JudiciaryGOP: Trump was right again, and again, and again, and again, and again.\n",
      "@HouseGOP Trump imposed nearly $80 billion worth of new taxes on Americans by levying tariffs on 1000s of products,‚Ä¶ https://t.co/0xoGtr4f4t\n"
     ]
    }
   ],
   "source": [
    "app.run(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
